#  LLM Vault

LLM Vault is a secure API access layer for Large Language Model (LLM) services using OAuth 2.0 or JWT-based authentication. It ensures only authorized users can query the model through a FastAPI service deployed on Kubernetes.

---

## Tech Stack

- **FastAPI** â€“ LLM API backend
- **Keycloak** â€“ Identity Provider (OAuth 2.0)
- **Envoy** â€“ API Gateway for token validation
- **Kubernetes** â€“ Container orchestration
- **Docker** â€“ Containerization
- **Istio** *(optional)* â€“ Secure service mesh (mTLS)

---

## Running Locally

    1. **Clone the repo**

        ```bash
        git clone https://github.com/your-username/llm-vault.git
        cd llm-vault

	2.	Set up virtual environment

        python -m venv llm_vault
        source llm_vault/bin/activate


	3.	Install dependencies

        pip install -r requirements.txt


	4.	Run the FastAPI app

        uvicorn app:app --reload


â¸»

ğŸ³ Docker (Optional)

docker build -t llm-vault .
docker run -d -p 8000:8000 llm-vault



â¸»

â˜¸ï¸ Kubernetes Deployment

kubectl apply -f deployment.yaml
kubectl apply -f service.yaml



â¸»

ğŸ” Authentication
	â€¢	Set up Keycloak (or Auth0) to issue OAuth 2.0 tokens
	â€¢	Envoy will validate tokens before routing requests
	â€¢	Only authorized users can access the LLM service

â¸»

ğŸ“‚ Project Structure

.
â”œâ”€â”€ app.py               # FastAPI app
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ deployment.yaml      # K8s deployment config
â”œâ”€â”€ service.yaml         # K8s service config
â””â”€â”€ .gitignore



â¸»

ğŸ“Œ TODO
	â€¢	Integrate Envoy token validation
	â€¢	Add full Keycloak config
	â€¢	Deploy to cloud provider (GKE/EKS/etc)

â¸»

ğŸ‘¥ Contributors
	â€¢	